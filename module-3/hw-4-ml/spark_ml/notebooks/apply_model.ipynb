{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://dd486c79897e:4040\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1599031835620)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, StringType}\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StringType}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 3.0.0\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputStreamPath: String = /home/jovyan/data/events-stream\n",
       "modelPath: String = /home/jovyan/models/spark-ml-model\n",
       "dataSchema: org.apache.spark.sql.types.StructType = StructType(StructField(tweet,StringType,true))\n",
       "inputDF: org.apache.spark.sql.DataFrame = [tweet: string]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputStreamPath = \"/home/jovyan/data/events-stream\"\n",
    "val modelPath = \"/home/jovyan/models/spark-ml-model\"\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val inputDF = spark\n",
    "    .readStream\n",
    "    .schema(dataSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .json(inputStreamPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel: org.apache.spark.ml.PipelineModel = pipeline_a2a460ee428f\n",
       "predictionDF: org.apache.spark.sql.DataFrame = [tweet: string, words: array<string> ... 4 more fields]\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sameModel = PipelineModel.load(modelPath)\n",
    "\n",
    "\n",
    "val predictionDF = sameModel.transform(inputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@3be7aac4\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|@AlteracVolley wh...|[@alteracvolley, ...|(1000,[18,26,63,1...|[5.02952448837956...|[0.50295244883795...|       0.0|\n",
      "|Just found I have...|[just, found, i, ...|(1000,[61,125,208...|[5.11777615296168...|[0.51177761529616...|       0.0|\n",
      "|Aw. Scarhead is m...|[aw., scarhead, i...|(1000,[2,17,61,20...|[4.93060780565622...|[0.49306078056562...|       1.0|\n",
      "|@brandelion still...|[@brandelion, sti...|(1000,[24,47,135,...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|@Votney_925 I hav...|[@votney_925, i, ...|(1000,[166,307,36...|[5.02952448837956...|[0.50295244883795...|       0.0|\n",
      "|@NAKEDdmblauren f...|[@nakeddmblauren,...|(1000,[3,17,18,13...|[5.07136912569089...|[0.50713691256908...|       0.0|\n",
      "| #shortstack #tok...|[, #shortstack, #...|(1000,[316,372,56...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|I LOVE MUSIC !!!!...|[i, love, music, ...|(1000,[17,91,240,...|[5.06993083151037...|[0.50699308315103...|       0.0|\n",
      "|@DavidGurteen Hey...|[@davidgurteen, h...|(1000,[17,337,341...|[4.02510954528520...|[0.40251095452852...|       1.0|\n",
      "|@RealDMitchell lo...|[@realdmitchell, ...|(1000,[240,341,38...|[4.58698254322744...|[0.45869825432274...|       1.0|\n",
      "|am ready for some...|[am, ready, for, ...|(1000,[86,314,344...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|@crazilazigurl I ...|[@crazilazigurl, ...|(1000,[209,335,37...|[5.02952448837956...|[0.50295244883795...|       0.0|\n",
      "|just woke up. hah...|[just, woke, up.,...|(1000,[97,307,451...|[5.09002596124897...|[0.50900259612489...|       0.0|\n",
      "| I just ruined 4t...|[, i, just, ruine...|(1000,[34,53,69,1...|[5.24704297535423...|[0.52470429753542...|       0.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|@Rhiamon I think ...|[@rhiamon, i, thi...|(1000,[20,66,206,...|[5.11792011235061...|[0.51179201123506...|       0.0|\n",
      "|Trying 2 not let ...|[trying, 2, not, ...|(1000,[39,112,152...|[5.02175291352916...|[0.50217529135291...|       0.0|\n",
      "|Worst movie: 'Zac...|[worst, movie:, '...|(1000,[113,299,33...|[5.04124126673280...|[0.50412412667328...|       0.0|\n",
      "|dear april, come ...|[dear, april,, co...|(1000,[4,17,43,44...|[4.85940685081125...|[0.48594068508112...|       1.0|\n",
      "|awake since six o...|[awake, since, si...|(1000,[287,401,48...|[5.24704297535423...|[0.52470429753542...|       0.0|\n",
      "|strange combo but...|[strange, combo, ...|(1000,[100,344,52...|[5.14535886567291...|[0.51453588656729...|       0.0|\n",
      "|SHOPAHOLIC!!! lol...|[shopaholic!!!, l...|(1000,[102,215,21...|[5.20126472441262...|[0.52012647244126...|       0.0|\n",
      "|@reinventlovekid ...|[@reinventlovekid...|(1000,[17,144,206...|[4.87678758308014...|[0.48767875830801...|       1.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     I hate Mondays |  [i, hate, mondays]|(1000,[69,756,808...|[5.02952448837956...|[0.50295244883795...|       0.0|\n",
      "|got high with my ...|[got, high, with,...|(1000,[9,10,99,11...|[5.43295074451688...|[0.54329507445168...|       0.0|\n",
      "|Is missing death ...|[is, missing, dea...|(1000,[99,209,299...|[5.11777615296168...|[0.51177761529616...|       0.0|\n",
      "|Not feeling the l...|[not, feeling, th...|(1000,[17,76,207,...|[4.83119742149647...|[0.48311974214964...|       1.0|\n",
      "|Don't have time t...|[don't, have, tim...|(1000,[25,71,157,...|[6.04423620400596...|[0.60442362040059...|       0.0|\n",
      "|Sucks, don't feel...|[sucks,, don't, f...|(1000,[115,168,74...|[4.73880881483682...|[0.47388088148368...|       1.0|\n",
      "|  @beatricetan who? |[@beatricetan, who?]|(1000,[529,830],[...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|@saintsammy I can't |[@saintsammy, i, ...|(1000,[457,580,75...|[5.02952448837956...|[0.50295244883795...|       0.0|\n",
      "|I hate it when I ...|[i, hate, it, whe...|(1000,[69,76,104,...|[5.40616931393865...|[0.54061693139386...|       0.0|\n",
      "|@ssashimii I only...|[@ssashimii, i, o...|(1000,[9,286,495,...|[5.02952448837956...|[0.50295244883795...|       0.0|\n",
      "|APPRENTICE FINAL ...|[apprentice, fina...|(1000,[110,208,21...|[4.73833649297314...|[0.47383364929731...|       1.0|\n",
      "|http://twitpic.co...|[http://twitpic.c...|(1000,[135,152,33...|[4.95316198200692...|[0.49531619820069...|       1.0|\n",
      "|Got back from the...|[got, back, from,...|(1000,[10,17,71,9...|[5.85411502254264...|[0.58541150225426...|       0.0|\n",
      "|waiting liih !! i...|[waiting, liih, !...|(1000,[17,209,226...|[5.25023041525800...|[0.5250230415258,...|       0.0|\n",
      "|Even triple-stren...|[even, triple-str...|(1000,[160,369,37...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|@kaylynashleyy Oh...|[@kaylynashleyy, ...|(1000,[209,249,37...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|going to paris fr...|[going, to, paris...|(1000,[38,299,364...|[4.94921694654593...|[0.49492169465459...|       1.0|\n",
      "|@Dovescorner and ...|[@dovescorner, an...|(1000,[22,344,359...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|Bye everyone, enj...|[bye, everyone,, ...|(1000,[17,36,76,1...|[4.66854724501904...|[0.46685472450190...|       1.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|On the way back t...|[on, the, way, ba...|(1000,[17,139,372...|[4.82054962490642...|[0.48205496249064...|       1.0|\n",
      "|Is attending a tw...|[is, attending, a...|(1000,[209,248,46...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|i want to go see ...|[i, want, to, go,...|(1000,[133,354,37...|[5.25858516766473...|[0.52585851676647...|       0.0|\n",
      "|@descarabe il be ...|[@descarabe, il, ...|(1000,[11,80,162,...|[5.10872144157880...|[0.51087214415788...|       0.0|\n",
      "|@maliajonas hahah...|[@maliajonas, hah...|(1000,[17,33,35,2...|[5.09971750200882...|[0.50997175020088...|       0.0|\n",
      "|@ian_si How cool ...|[@ian_si, how, co...|(1000,[57,59,157,...|[5.28502163932133...|[0.52850216393213...|       0.0|\n",
      "|Browsing the Web ...|[browsing, the, w...|(1000,[17,148,349...|[4.86096528196380...|[0.48609652819638...|       1.0|\n",
      "|stacia again: the...|[stacia, again:, ...|(1000,[10,17,35,5...|[5.41637927455361...|[0.54163792745536...|       0.0|\n",
      "|Thanks Bolivia - ...|[thanks, bolivia,...|(1000,[110,152,16...|[4.88426659505593...|[0.48842665950559...|       1.0|\n",
      "|Hi everyone .. Av...|[hi, everyone, .....|(1000,[44,152,166...|[4.97564876372022...|[0.49756487637202...|       1.0|\n",
      "|@QuinnAston hahah...|[@quinnaston, hah...|(1000,[24,215,276...|[4.82074628761140...|[0.48207462876114...|       1.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val query = predictionDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) =>\n",
    "    batchDF.show()\n",
    "}.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "getProbability: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$4815/0x0000000841799040@301ee573,DoubleType,List(Some(class[value[0]: vector])),None,false,true)\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@43bd5098\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "|0.49704755116204347|\n",
      "|0.48822238470383106|\n",
      "| 0.5069392194343771|\n",
      "| 0.5139034718036193|\n",
      "|0.49704755116204347|\n",
      "|0.49286308743091023|\n",
      "| 0.5139034718036193|\n",
      "| 0.4930069168489628|\n",
      "| 0.5974890454714797|\n",
      "| 0.5413017456772555|\n",
      "| 0.5139034718036193|\n",
      "|0.49704755116204347|\n",
      "| 0.4909974038751022|\n",
      "|0.47529570246457664|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "| 0.4882079887649381|\n",
      "|0.49782470864708317|\n",
      "| 0.4958758733267194|\n",
      "| 0.5140593149188744|\n",
      "|0.47529570246457664|\n",
      "| 0.4854641134327083|\n",
      "| 0.4798735275587374|\n",
      "| 0.5123212416919851|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "|0.49704755116204347|\n",
      "|0.45670492554831155|\n",
      "|0.48822238470383106|\n",
      "| 0.5168802578503527|\n",
      "|0.39557637959940356|\n",
      "|  0.526119118516318|\n",
      "| 0.5139034718036193|\n",
      "|0.49704755116204347|\n",
      "| 0.4593830686061343|\n",
      "|0.49704755116204347|\n",
      "| 0.5261663507026854|\n",
      "| 0.5046838017993076|\n",
      "|0.41458849774573603|\n",
      "|0.47497695847419985|\n",
      "| 0.5139034718036193|\n",
      "| 0.5139034718036193|\n",
      "|  0.505078305345407|\n",
      "| 0.5139034718036193|\n",
      "| 0.5331452754980955|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "| 0.5179450375093577|\n",
      "| 0.5139034718036193|\n",
      "|0.47414148323352634|\n",
      "| 0.4891278558421198|\n",
      "|0.49002824979911785|\n",
      "|0.47149783606786694|\n",
      "| 0.5139034718036193|\n",
      "| 0.4583620725446388|\n",
      "|  0.511573340494407|\n",
      "| 0.5024351236279778|\n",
      "| 0.5179253712388598|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val query = predictionDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) =>\n",
    "    batchDF.select(getProbability($\"probability\").alias(\"clean_probability\")).show\n",
    "}.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
